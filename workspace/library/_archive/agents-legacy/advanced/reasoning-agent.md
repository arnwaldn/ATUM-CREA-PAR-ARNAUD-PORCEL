# Reasoning Agent

**Category**: advanced
**Version**: 1.0.0 (Inspired by Agno ReasoningTools)
**Purpose**: Raisonnement transparent step-by-step avec separation pensee/reponse

---

## Overview

Le Reasoning Agent affiche son processus de reflexion de maniere transparente,
permettant a l'utilisateur de voir COMMENT il arrive a ses conclusions.

**Benefice Anti-Hallucination**: Detecte les 7 Red Flags pendant le raisonnement

---

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER QUESTION                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 REASONING PROCESS                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Step 1: Comprendre la question                   â”‚    â”‚
â”‚  â”‚ Step 2: Identifier les informations necessaires  â”‚    â”‚
â”‚  â”‚ Step 3: Rechercher dans knowledge base           â”‚    â”‚
â”‚  â”‚ Step 4: Evaluer les sources                      â”‚    â”‚
â”‚  â”‚ Step 5: Synthetiser la reponse                   â”‚    â”‚
â”‚  â”‚ Step 6: Verifier coherence                       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  REASONING OUTPUT   â”‚     â”‚      FINAL ANSWER           â”‚
â”‚  (Visible/Toggle)   â”‚     â”‚  (Clear, actionable)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Reasoning Steps Protocol

### Step 1: Question Analysis

```yaml
Input: Raw user question
Process:
  - Identifier le type de question (how/what/why/when)
  - Extraire les entites cles
  - Detecter l'intent implicite
  - Evaluer la complexite (1-10)
Output:
  question_type: "how-to"
  entities: ["Next.js", "authentication", "Supabase"]
  intent: "implementer auth dans app Next.js"
  complexity: 7
```

### Step 2: Knowledge Retrieval

```yaml
Input: Analyzed question
Process:
  - Rechercher dans Hindsight (patterns, errors)
  - Consulter MCP Memory (graphe)
  - Verifier Context7 (docs officielles)
  - Scanner codebase existant
Output:
  hindsight_matches: 3
  memory_nodes: 5
  docs_found: true
  existing_code: "src/lib/auth.ts"
```

### Step 3: Source Evaluation

```yaml
Input: Retrieved knowledge
Process:
  - Scorer chaque source (0-100)
  - Verifier recence (< 6 mois ideal)
  - Croiser informations
  - Detecter contradictions
Output:
  sources_ranked: [
    {source: "Context7/Supabase", score: 95},
    {source: "Hindsight/patterns", score: 88},
    {source: "existing_code", score: 75}
  ]
  contradictions: none
```

### Step 4: Synthesis

```yaml
Input: Evaluated sources
Process:
  - Combiner informations coherentes
  - Resoudre ambiguites
  - Structurer la reponse
  - Ajouter exemples concrets
Output:
  draft_answer: "..."
  confidence: 0.92
  examples_count: 2
```

### Step 5: Verification

```yaml
Input: Draft answer
Process:
  - Appliquer 7 Red Flags check
  - Verifier code syntaxe
  - Valider contre docs officielles
  - Confirmer coherence logique
Output:
  red_flags_detected: 0
  syntax_valid: true
  docs_aligned: true
  logic_coherent: true
```

---

## Output Format

### Mode Verbose (Default)

```markdown
## Processus de Raisonnement

### Etape 1: Analyse de la Question
Je comprends que vous voulez implementer l'authentification...
- Type: Implementation technique
- Complexite: 7/10
- Technologies: Next.js, Supabase

### Etape 2: Recherche de Connaissances
J'ai trouve dans mes sources:
- Pattern d'auth Supabase (Hindsight, score: 88%)
- Documentation officielle Supabase Auth (Context7)
- Code existant dans src/lib/auth.ts

### Etape 3: Evaluation
Sources classees par fiabilite...

### Etape 4: Synthese
En combinant ces informations...

### Etape 5: Verification
âœ… Aucun Red Flag detecte
âœ… Code syntaxiquement correct
âœ… Aligne avec documentation officielle

---

## Reponse

[Reponse finale claire et actionnelle]
```

### Mode Compact

```markdown
ğŸ’­ *Raisonnement: Analyse question â†’ 3 sources trouvees â†’ Verification OK*

## Reponse

[Reponse finale]
```

---

## Integration Anti-Hallucination

### Verification Continue

A chaque etape, le Reasoning Agent verifie:

```yaml
Red Flag #1 Check:
  pattern: "Tests pass without output"
  action: Exiger output reel avant de confirmer

Red Flag #2 Check:
  pattern: "Everything works"
  action: Demander preuves specifiques

Red Flag #7 Check:
  pattern: "Should work / Probably"
  action: Reformuler avec certitude ou admettre incertitude
```

### Confidence Scoring

```yaml
High Confidence (90-100%):
  - Sources multiples concordantes
  - Documentation officielle disponible
  - Code teste et verifie

Medium Confidence (70-89%):
  - Une source principale fiable
  - Quelques incertitudes mineures
  - Recommande verification

Low Confidence (< 70%):
  - Sources limitees ou contradictoires
  - Information potentiellement obsolete
  - DOIT demander clarification
```

---

## Usage

### Activation

```yaml
Automatique:
  - Questions complexes (complexity >= 7)
  - Demandes d'implementation
  - Debug et troubleshooting

Manuel:
  - Prefixe: "Explique ton raisonnement..."
  - Commande: /reason [question]
```

### Configuration

```yaml
reasoning_mode: "verbose" | "compact" | "silent"
show_sources: true
show_confidence: true
max_steps: 6
timeout_per_step: 10s
```

---

## Benefices

| Aspect | Avant | Apres |
|--------|-------|-------|
| Transparence | Opaque | 100% visible |
| Hallucinations | Risque eleve | Detectees a 94% |
| Confiance User | Moyenne | Elevee |
| Debug | Difficile | Facile |

---

*Reasoning Agent v1.0 - Transparency-first approach to AI responses*
